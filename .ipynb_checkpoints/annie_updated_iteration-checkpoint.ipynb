{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfad1e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import json\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.spatial.distance import cdist, cosine, euclidean\n",
    "from scipy.stats import ttest_ind, ttest_1samp\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from gpu_utils import restrict_GPU_pytorch\n",
    "\n",
    "import torch\n",
    "from transformers import DistilBertModel\n",
    "from transformers import DistilBertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b5ec5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:3\n"
     ]
    }
   ],
   "source": [
    "restrict_GPU_pytorch('3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27eb67f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FPATH = '../data/reddit/'\n",
    "MODEL_FPATH = '../models/reddit/'\n",
    "USE_PATH = '../Dev/tf_hub/universal-sentence-encoder_4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a9c46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = ['askscience', 'conspiracy', 'funny', 'hillaryclinton', 'history']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88050177",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a995422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>moderated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>You can tell this is fake because it shows a b...</td>\n",
       "      <td>funny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>They're purple because she's dead.\\n\\nLol sorr...</td>\n",
       "      <td>hillaryclinton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The fat lady is singing.</td>\n",
       "      <td>funny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Good thing volks never break down. XD Shitty k...</td>\n",
       "      <td>funny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm dreaming of a bright christmas.\\n</td>\n",
       "      <td>funny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               body  \\\n",
       "0           0  You can tell this is fake because it shows a b...   \n",
       "1           1  They're purple because she's dead.\\n\\nLol sorr...   \n",
       "2           2                           The fat lady is singing.   \n",
       "3           3  Good thing volks never break down. XD Shitty k...   \n",
       "4           5              I'm dreaming of a bright christmas.\\n   \n",
       "\n",
       "        subreddit  moderated  \n",
       "0           funny          1  \n",
       "1  hillaryclinton          1  \n",
       "2           funny          1  \n",
       "3           funny          1  \n",
       "4           funny          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments = pd.read_csv(DATA_FPATH + 'all_comments_df')\n",
    "all_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b7c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 'funny'\n",
    "comments = all_comments[all_comments.subreddit == sub].body.values\n",
    "labels = all_comments[all_comments.subreddit == sub].moderated.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305d6727",
   "metadata": {},
   "source": [
    "### Next steps: Annie\n",
    "\n",
    "Example search & generation has three main steps (though they may be intertwined in some ways): 1) getting similar examples, 2) clustering or organizing them in some way 3) visualizing the result.  Right now we're doing 1) with euclidean distance in embedding space of the USE, 2) with k-means clustering, and 3) with just printing out the examples. \n",
    "\n",
    "We can think about ways to improve each of these parts.  To start, let's explore 1).  Right now we are getting similar examples with the USE (the model we load from TF Hub).  How does this compare to a different embedding model?  Here are some we can try: \n",
    "* BERT: https://huggingface.co/bert-base-uncased\n",
    "* RoBERTa: https://huggingface.co/roberta-base\n",
    "* XLNet: https://huggingface.co/xlnet-base-cased\n",
    "\n",
    "Later, we could also think about fine-tuning some of these embeddings to be better suited to our task/data.  Sample code for loading BERT and getting embeddings for a sample of sentences: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b2d08d",
   "metadata": {},
   "source": [
    "### To do: \n",
    "* modify `getKNNFromVector` to take a particular embedding name (e.g., 'BERT') and compute distances in that embedding space. \n",
    "* for a handful of seed sentences, get the nearest neighbors and print them out as above in each of the different embedding spaces. Qualitatively note differences you notice among what is returned as similar. Do some seem better or worse?  Are there noticeable differences? \n",
    "* for an easy 2 or 3D projection, you can try loading the data into the embedding projector: https://projector.tensorflow.org/  You may want to just do a particular example and its 100 nearest neighbors or something (rather than all the data). You'll have to save the embeddings and sentences as TSV files and then load them in. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df95fafa",
   "metadata": {},
   "source": [
    "#### BERT embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2045b2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8bf0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = tokenizer(list(comments), padding=True, truncation=True, return_tensors=\"pt\")['input_ids']\n",
    "tokenized_comments = tokenized_sentences.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aed4df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34347, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c80e153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f0501d98a14aea8643573ecdbc116a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34347.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_output = np.concatenate(tuple([model(tokenized_comments[i:i+1])['last_hidden_state'].cpu().detach().numpy() for i in tqdm(range(len(comments)))]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "571f2b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34347, 512, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fcb2f1",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f84525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_shift(shift_target, example_list, example_list_2, model, labels = None, labels_2 = None, list_names=[\"list 1\", \"list 2\"]): \n",
    "    if shift_target == \"predictions\":\n",
    "        preds_1 = getModelPredsHelper(example_list, model)\n",
    "        preds_2 = getModelPredsHelper(example_list_2, model)\n",
    "        ttest_result = ttest_ind(preds_1, preds_2)\n",
    "        if ttest_result.pvalue >= 0.05: \n",
    "            print(\"Predictions are not significantly different.\")\n",
    "        else: \n",
    "            operator = \"higher\" if ttest_result.statistic > 0 else \"lower\"\n",
    "            print(\"P(moderated) for %s is *%s* than for %s (pval = %.3f)\" % (list_names[0], operator, list_names[1], ttest_result.pvalue))\n",
    "            \n",
    "            \n",
    "    elif shift_target == \"representation\":\n",
    "        vecs_1 = [model.get_sentence_vector(ex) for ex in example_list]\n",
    "        vecs_2 = [model.get_sentence_vector(ex) for ex in example_list_2]\n",
    "        intergroup_diffs = cdist(vecs_1, vecs_2).flatten()\n",
    "        intragroup_diffs = np.concatenate((cdist(vecs_1, vecs_1).flatten(), cdist(vecs_2, vecs_2).flatten()))\n",
    "        ttest_result = ttest_ind(intergroup_diffs, intragroup_diffs)\n",
    "        if ttest_result.statistic > 0 and ttest_result.pvalue < 0.05: \n",
    "            print(\"Representations for %s are significantly different from %s (pval = %f).\" % (list_names[0], list_names[1], ttest_result.pvalue))\n",
    "        else: \n",
    "            print(\"Representations for %s and %s are not significantly different.\" % (list_names[0], list_names[1]))\n",
    "            \n",
    "            \n",
    "    elif shift_target == \"performance\":\n",
    "        preds_1 = getModelPredsHelper(example_list, model)\n",
    "        preds_2 = getModelPredsHelper(example_list_2, model)\n",
    "        perf_1 = np.array([np.round(preds_1[i]) == labels[i] for i in range(len(preds_1))]).astype(int)\n",
    "        perf_2 = np.array([np.round(preds_2[i]) == labels_2[i] for i in range(len(preds_2))]).astype(int)\n",
    "        ttest_result = ttest_ind(perf_1, perf_2)\n",
    "        if ttest_result.pvalue >= 0.05: \n",
    "            print(\"Model performance on %s and %s is not significantly different.\" % (list_names[0], list_names[1]))\n",
    "        else: \n",
    "            operator = \"higher\" if ttest_result.statistic > 0 else \"lower\"\n",
    "            print(\"Model performance on %s is *%s* than for %s (pval = %.3f)\" % (list_names[0], operator, list_names[1], ttest_result.pvalue))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
