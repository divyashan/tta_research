{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6850968a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Set-up: Import numpy and assign GPU\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from gpu_utils import restrict_GPU_pytorch\n",
    "restrict_GPU_pytorch('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a19c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Amazon WILDS pre-trained model\n",
    "import statistics\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import argparse\n",
    "import pdb\n",
    "\n",
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_train_loader, get_eval_loader\n",
    "from wilds.common.grouper import CombinatorialGrouper\n",
    "from transforms_helenl import initialize_transform, getBertTokenizer\n",
    "\n",
    "sys.path.insert(0, './wilds/examples/')\n",
    "from algorithms.initializer import initialize_algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3eab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3d1d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        \n",
    "#config_dict = pickle.load(open('amazon_config.txt', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "full_dataset = get_dataset(dataset='civilcomments', download=False, root_dir = './wilds/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa167a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'civilcomments',\n",
       " 'algorithm': 'ERM',\n",
       " 'root_dir': 'data',\n",
       " 'split_scheme': 'official',\n",
       " 'dataset_kwargs': {},\n",
       " 'download': False,\n",
       " 'frac': 1.0,\n",
       " 'version': None,\n",
       " 'loader_kwargs': {'num_workers': 1, 'pin_memory': True},\n",
       " 'train_loader': 'standard',\n",
       " 'uniform_over_groups': False,\n",
       " 'distinct_groups': None,\n",
       " 'n_groups_per_batch': 4,\n",
       " 'batch_size': 16,\n",
       " 'eval_loader': 'standard',\n",
       " 'model': 'distilbert-base-uncased',\n",
       " 'model_kwargs': {},\n",
       " 'transform': 'bert',\n",
       " 'target_resolution': None,\n",
       " 'resize_scale': None,\n",
       " 'max_token_length': 300,\n",
       " 'loss_function': 'cross_entropy',\n",
       " 'loss_kwargs': {},\n",
       " 'groupby_fields': ['black', 'y'],\n",
       " 'group_dro_step_size': None,\n",
       " 'coral_penalty_weight': 10.0,\n",
       " 'irm_lambda': 1.0,\n",
       " 'irm_penalty_anneal_iters': None,\n",
       " 'algo_log_metric': 'accuracy',\n",
       " 'val_metric': 'acc_wg',\n",
       " 'val_metric_decreasing': False,\n",
       " 'n_epochs': 5,\n",
       " 'optimizer': 'AdamW',\n",
       " 'lr': 1e-05,\n",
       " 'weight_decay': 0.01,\n",
       " 'max_grad_norm': 1.0,\n",
       " 'optimizer_kwargs': {},\n",
       " 'scheduler': 'linear_schedule_with_warmup',\n",
       " 'scheduler_kwargs': {'num_warmup_steps': 0},\n",
       " 'scheduler_metric_split': 'val',\n",
       " 'scheduler_metric_name': None,\n",
       " 'process_outputs_function': 'multiclass_logits_to_pred',\n",
       " 'evaluate_all_splits': True,\n",
       " 'eval_splits': [],\n",
       " 'eval_only': False,\n",
       " 'eval_epoch': None,\n",
       " 'device': 0,\n",
       " 'seed': 0,\n",
       " 'log_dir': './logs',\n",
       " 'log_every': 50,\n",
       " 'save_step': None,\n",
       " 'save_best': True,\n",
       " 'save_last': True,\n",
       " 'save_pred': True,\n",
       " 'no_group_logging': False,\n",
       " 'use_wandb': False,\n",
       " 'progress_bar': False,\n",
       " 'resume': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Grab config generated by WILDS library from txt file\n",
    "    infile = open('civilcomments_config.txt','rb')\n",
    "    new_dict = vars(pickle.load(infile))\n",
    "    infile.close() \n",
    "\n",
    "    # Create config with ERM algorithm\n",
    "    config = Namespace(**new_dict)\n",
    "\n",
    "    new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "310d5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_augmented_labels(transform_name):\n",
    "    \n",
    "    # Grab config generated by WILDS library from txt file\n",
    "    infile = open('civilcomments_config.txt','rb')\n",
    "    new_dict = vars(pickle.load(infile))\n",
    "    infile.close() \n",
    "\n",
    "    # Modify config with intended transformation\n",
    "    new_dict['transform'] = transform_name\n",
    "\n",
    "    # Create config with ERM algorithm\n",
    "    config = Namespace(**new_dict)\n",
    "    config.algorithm = 'ERM'\n",
    "\n",
    "    \n",
    "    # Generate training and evaluation transforms\n",
    "    train_transform = initialize_transform(transform_name=config.transform,\n",
    "                                      config=config,\n",
    "                                      dataset=full_dataset,\n",
    "                                      is_training=True)\n",
    "    eval_transform = initialize_transform(transform_name=config.transform,\n",
    "                                      config=config,\n",
    "                                      dataset=full_dataset,\n",
    "                                      is_training=False)\n",
    "    \n",
    "    \n",
    "    # Prepare training data, loader, and grouper\n",
    "    train_data = full_dataset.get_subset('train', transform=train_transform)\n",
    "    train_loader = get_train_loader('standard', train_data, batch_size=64)\n",
    "    train_grouper = CombinatorialGrouper(dataset=full_dataset, groupby_fields=config.groupby_fields)\n",
    "    \n",
    "        # Prepare training data, loader, and grouper\n",
    "        \n",
    "    eval_data = full_dataset.get_subset('test', transform=eval_transform)\n",
    "    eval_loader = get_eval_loader('standard', eval_data, batch_size = 64)\n",
    "    \n",
    "    # CODE TAKEN FROM WILDS TRAINING SCRIPTS:\n",
    "    datasets = defaultdict(dict)\n",
    "    for split in full_dataset.split_dict.keys():\n",
    "        if split=='train':\n",
    "            transform = train_transform\n",
    "            verbose = True\n",
    "        elif split == 'val':\n",
    "            transform = eval_transform\n",
    "            verbose = True\n",
    "        else:\n",
    "            transform = eval_transform\n",
    "            verbose = False\n",
    "        # Get subset\n",
    "        datasets[split]['dataset'] = full_dataset.get_subset(\n",
    "            split,\n",
    "            frac=config.frac,\n",
    "            transform=transform)\n",
    "\n",
    "        if split == 'train':\n",
    "            datasets[split]['loader'] = get_train_loader(\n",
    "                loader=config.train_loader,\n",
    "                dataset=datasets[split]['dataset'],\n",
    "                batch_size=config.batch_size,\n",
    "                uniform_over_groups=config.uniform_over_groups,\n",
    "                grouper=train_grouper,\n",
    "                distinct_groups=config.distinct_groups,\n",
    "                n_groups_per_batch=config.n_groups_per_batch,\n",
    "            **config.loader_kwargs)\n",
    "        else:\n",
    "            datasets[split]['loader'] = get_eval_loader(\n",
    "                loader=config.eval_loader,\n",
    "                dataset=datasets[split]['dataset'],\n",
    "                grouper=train_grouper,\n",
    "                batch_size=config.batch_size,\n",
    "                **config.loader_kwargs)\n",
    "\n",
    "    # Set fields\n",
    "    datasets[split]['split'] = split\n",
    "    datasets[split]['name'] = full_dataset.split_names[split]\n",
    "    datasets[split]['verbose'] = verbose\n",
    "\n",
    "    # Loggers\n",
    "    # datasets[split]['eval_logger'] = BatchLogger(\n",
    "    #     os.path.join(config.log_dir, f'{split}_eval.csv'), mode=mode, use_wandb=(config.use_wandb and verbose))\n",
    "    # datasets[split]['algo_logger'] = BatchLogger(\n",
    "    #     os.path.join(config.log_dir, f'{split}_algo.csv'), mode=mode, use_wandb=(config.use_wandb and verbose))\n",
    "\n",
    "    print(transform_name)\n",
    "    print(\"initialize model\")\n",
    "    # Initiate model and run on training set\n",
    "    alg = initialize_algorithm(config, datasets, train_grouper)\n",
    "    \n",
    "    # TODO: pytorch load pretrained weights\n",
    "    #alg.model.load_state_dict(torch.load('./best_model.pth'))\n",
    "    alg.load_state_dict(torch.load('./best_model.pth')['algorithm'])\n",
    "    alg.model.cuda()\n",
    "    \n",
    "    print(\"initialization complete\")\n",
    "    \n",
    "    \n",
    "    print(\"generating predictions\")\n",
    "    it = iter(eval_loader)\n",
    "    predictions = []\n",
    "    true_values = []\n",
    "    \n",
    "    for batch in tqdm(it):\n",
    "        \n",
    "        #pdb.set_trace()\n",
    "        raw_pred = alg.model(batch[0].cuda()).cpu().detach().numpy().tolist()\n",
    "        #softmax_prediction = sp.special.softmax(raw_pred.cpu().detach().numpy()).tolist()\n",
    "        predictions.append(raw_pred)\n",
    "        true_values.extend(batch[1].tolist())\n",
    "    \n",
    "\n",
    "    print(\"writing predictions\")\n",
    "    file_name = './ERM_predictions/' + transform_name + \".npy\"\n",
    "    \n",
    "    with open(file_name, 'wb+') as file:\n",
    "        np.save(file, predictions)\n",
    "        np.save(file, true_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2a3def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(prediction_file):\n",
    "    logit_predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(prediction_file, 'rb') as file:\n",
    "        logit_predictions = np.load(file, allow_pickle = True)\n",
    "        labels = np.load(file, allow_pickle = True)\n",
    "    \n",
    "    '''\n",
    "    print(len(logit_predictions[0]))\n",
    "    print(type(logit_predictions))\n",
    "    print(logit_predictions)\n",
    "    '''\n",
    "    \n",
    "    softmaxed_predictions = []\n",
    "    \n",
    "    for pred in logit_predictions[0]:\n",
    "        softmax = sp.special.softmax(pred).tolist()\n",
    "        softmaxed_predictions.append(softmax[1])\n",
    "        \n",
    "    #plt.hist(logit_predictions)\n",
    "    #plt.hist(softmaxed_predictions)\n",
    "    \n",
    "    #return sklearn.metrics.roc_auc_score(labels[:64], softmaxed_predictions)\n",
    "\n",
    "    classified_predictions = []\n",
    "    for prediction in logit_predictions:\n",
    "        index_prediction = np.argmax(prediction, axis = 1).tolist()\n",
    "        \n",
    "        classified_predictions.extend(index_prediction)\n",
    "    \n",
    "    unique, counts = np.unique(np.array(classified_predictions), return_counts = True)\n",
    "    print(unique, counts)\n",
    "    print(len(labels))\n",
    "        \n",
    "    print(\"PREDICTIONS:\", len(classified_predictions))\n",
    "    #print(\"PREDICTIONS SAMPLE:\", classified_predictions[0])\n",
    "    print(\"TRUE VALUES:\", len(labels))\n",
    "    #print(\"TRUE VALUES SAMPLE:\", len(labels[0]))\n",
    "    #print(type(true_values))\n",
    "    \n",
    "    score = sklearn.metrics.accuracy_score(labels, classified_predictions)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3586c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(prediction_file):\n",
    "    logit_predictions = []\n",
    "    \n",
    "    with open(prediction_file, 'rb') as file:\n",
    "        logit_predictions = np.load(file)\n",
    "        true_values = np.load(file)\n",
    "        \n",
    "    print(true_values)\n",
    "    classified_predictions = []\n",
    "    for prediction in logit_predictions:\n",
    "        if prediction[0][0] > prediction[0][1]:\n",
    "            classified_predictions.append(0)\n",
    "            \n",
    "        else:\n",
    "            classified_predictions.append(1)\n",
    "    \n",
    "    score = sklearn.metrics.recall_score(true_values, classified_predictions)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64cf1cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\n",
      "initialize model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertClassifier: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertClassifier were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization complete\n",
      "generating predictions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3273a006cda4960ad9c8b5113481e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/helenl/.conda/envs/tta/lib/python3.6/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "predict_augmented_labels('bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0853c844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [120992  12790]\n",
      "133782\n",
      "PREDICTIONS: 133782\n",
      "TRUE VALUES: 133782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9266418501741639"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "calculate_accuracy('./ERM_predictions/bert.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b926163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_distribution(prediction_file):\n",
    "    logit_predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(prediction_file, 'rb') as file:\n",
    "        logit_predictions = np.load(file, allow_pickle = True)\n",
    "        labels = np.load(file, allow_pickle = True)\n",
    "    \n",
    "    softmaxed_predictions = []\n",
    "    \n",
    "    for pred in logit_predictions[0]:\n",
    "        softmax = sp.special.softmax(pred).tolist()\n",
    "        softmaxed_predictions.append(softmax[1])\n",
    "        \n",
    "    plt.hist(logit_predictions)\n",
    "    plt.hist(softmaxed_predictions)\n",
    "    \n",
    "    #return sklearn.metrics.roc_auc_score(labels[:64], softmaxed_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79c3a4ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7b4e54588d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_prediction_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ERM_predictions/bert.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-49b7d50c161a>\u001b[0m in \u001b[0;36mplot_prediction_distribution\u001b[0;34m(prediction_file)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msoftmaxed_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmaxed_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/helenl/.conda/envs/tta/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, normed, data, **kwargs)\u001b[0m\n\u001b[1;32m   2640\u001b[0m         \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2641\u001b[0m         \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2642\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/helenl/.conda/envs/tta/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/helenl/.conda/envs/tta/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, normed, **kwargs)\u001b[0m\n\u001b[1;32m   6841\u001b[0m                 patch = _barfunc(bins[:-1]+boffset, height, width,\n\u001b[1;32m   6842\u001b[0m                                  \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m                                  color=c, **{bottom_kwarg: bottom})\n\u001b[0m\u001b[1;32m   6844\u001b[0m                 \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/helenl/.conda/envs/tta/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/helenl/.conda/envs/tta/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2428\u001b[0m                 \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2429\u001b[0m                 \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2430\u001b[0;31m                 \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_nolegend_'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2431\u001b[0m                 )\n\u001b[1;32m   2432\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/helenl/.conda/envs/tta/lib/python3.6/site-packages/matplotlib/patches.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xy, width, height, angle, **kwargs)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \"\"\"\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0mPatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/helenl/.conda/envs/tta/lib/python3.6/site-packages/matplotlib/patches.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, edgecolor, facecolor, color, linewidth, linestyle, antialiased, hatch, fill, capstyle, joinstyle, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medgecolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;31m# unscaled dashes.  Needed to scale dash patterns by lw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_us_dashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/helenl/.conda/envs/tta/lib/python3.6/site-packages/matplotlib/patches.py\u001b[0m in \u001b[0;36mset_facecolor\u001b[0;34m(self, color)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \"\"\"\n\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_facecolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/helenl/.conda/envs/tta/lib/python3.6/site-packages/matplotlib/patches.py\u001b[0m in \u001b[0;36m_set_facecolor\u001b[0;34m(self, color)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'patch.facecolor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fill\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_facecolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_prediction_distribution('./ERM_predictions/bert.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e23e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_roc_auc_score(prediction_file):\n",
    "    logit_predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(prediction_file, 'rb') as file:\n",
    "        logit_predictions = np.load(file, allow_pickle = True)\n",
    "        labels = np.load(file, allow_pickle = True)\n",
    "    \n",
    "    softmaxed_predictions = []\n",
    "    \n",
    "    for batch in logit_predictions:\n",
    "        for pred in batch:\n",
    "            softmax = sp.special.softmax(pred).tolist()\n",
    "            softmaxed_predictions.append(softmax[1])\n",
    "        \n",
    "    \n",
    "    return sklearn.metrics.roc_auc_score(labels, softmaxed_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b76683a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5346635574609436"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_roc_auc_score('./ERM_predictions/bert.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cdc9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
